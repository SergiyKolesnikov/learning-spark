{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a97f35-32ca-4e73-b0a0-5f8763b8c211",
   "metadata": {},
   "source": [
    "# Chapter 8. Structured Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bcf7a7-ba94-4f12-a75e-4db2a936afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "  # Add Kafka-source library.  The version after \":\" must be the Kafka version that you use  \n",
    "  .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0\")\n",
    "  .master(\"local[4]\")\n",
    "  .appName(\"StructuredStreaming\")\n",
    "  .getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af97418-4748-4a08-852f-a9f88eb4db6d",
   "metadata": {},
   "source": [
    "## The Fundamentals of a Structured Streaming Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f951e-ef74-498e-b2e1-f67bdf4d7665",
   "metadata": {},
   "source": [
    "For the following streaming query to work, we need a TCP server that will listen at `127.0.0.1:61080` and will be sending text lines.\n",
    "\n",
    "We can use `netcat-openbsd` for this. In a terminal run `nc -lk -s 127.0.0.1 -p 61080` and start typing text lines. Observe the output in this notebook. It should be something like this\n",
    "\n",
    "```\n",
    "-------------------------------------------\n",
    "Batch: 1\n",
    "-------------------------------------------\n",
    "+----+-----+\n",
    "|word|count|\n",
    "+----+-----+\n",
    "| foo|    1|\n",
    "+----+-----+\n",
    "```\n",
    "\n",
    "To terminate the query interrupt the Jupyter kernel (menu Krenel -> Interrupt Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9adc70b-a77c-4ada-80ad-ad0c5d8832f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = f\"/tmp/spark-streaming-checkpoints-{uuid1()}\"\n",
    "# checkpoint_dir = f\"./spark-streaming-checkpoints\"\n",
    "lines = (spark\n",
    "         .readStream\n",
    "         .format(\"socket\")\n",
    "         .option(\"host\", \"127.0.0.1\")\n",
    "         .option(\"port\", \"61080\")\n",
    "         .load())\n",
    "words = lines.select(F.explode(F.split(F.col(\"value\"), \"\\\\s\")).alias(\"word\"))\n",
    "counts = words.groupBy(\"word\").count()\n",
    "streaming_query = (counts\n",
    "                   .writeStream\n",
    "                   .format(\"console\")\n",
    "                   .outputMode(\"complete\")\n",
    "                   .trigger(processingTime=\"1 second\")\n",
    "                   .option(\"checkpointLocation\", checkpoint_dir)\n",
    "                   .start())\n",
    "streaming_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3938fec-08a7-4c34-a988-294bb5f82464",
   "metadata": {},
   "source": [
    "## Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee04a9-6bad-4db1-9775-4e9809556a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"`word` string, `count` long\"\n",
    "counts_sdf = spark.readStream.format(\"csv\").schema(schema).option(\"header\", \"true\").load(\"../data/counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afc3a9-e30f-47e3-a4d0-db55e8423905",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = f\"/tmp/spark-streaming-checkpoints-{uuid1()}\"\n",
    "streamingQuery = (counts_sdf\n",
    "  .selectExpr(\n",
    "    \"cast(word as string) as key\",\n",
    "    \"cast(count as string) as value\")\n",
    "  .writeStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9093,localhost:9094,localhost:9095\")\n",
    "  .option(\"topic\", \"wordcounts\")\n",
    "  .outputMode(\"update\")\n",
    "  .option(\"checkpointLocation\", checkpoint_dir)\n",
    "  .start())\n",
    "# If the counts are not written to the Kafka topic,\n",
    "# check the terminal where you started the notebook for error logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85b7e5-54a7-4451-b258-472a29e78878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
