{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd740a5-e77c-4d9e-b8fb-518f33a03c5c",
   "metadata": {},
   "source": [
    "# Chapter 9. Building Reliable Data Lakes with Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe346d-af2a-4e66-a599-9612aac54e36",
   "metadata": {},
   "source": [
    "## Building Lakehouses with Apache Spark and Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c17f8-06fc-4119-9aee-c12cefe27e34",
   "metadata": {},
   "source": [
    "### Configuring Apache Spark with Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf04b8-d8f8-40e6-99bc-6e6b82c4e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "from time import sleep\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "  # Add Maven coordinates of the Delta Lake jars as described in https://docs.delta.io/latest/quick-start.html#maven\n",
    "  .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\")\n",
    "  # Configure Delta Lake\n",
    "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "  .master(\"local[4]\")\n",
    "  .appName(\"DeltaLakes\")\n",
    "  .getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441863f-c177-4172-8cb2-6fc4c8eff8e3",
   "metadata": {},
   "source": [
    "### Loading Data into a Delta Lake Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67af829-2e28-42e3-9f7e-4cbf65190ce4",
   "metadata": {},
   "source": [
    "NOTE: Make sure that there is no a delta table in the directory specified as `deltaPath`. Otherwise, delete the directory by executing `rm data_output/loans_delta -rf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52956e08-c21c-4ddf-8703-acb6cbdad0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"set spark.sql.shuffle.partitions = 1\")\n",
    "\n",
    "# Source data path\n",
    "sourcePath = \"../data/loans/loan-risks.snappy.parquet\"\n",
    "# Delta Lake path\n",
    "deltaPath = \"../data_output/loans_delta\"\n",
    "# Create the Delta Lake table with the same loans data\n",
    "spark.read.format(\"parquet\").load(sourcePath).write.format(\"delta\").save(deltaPath)\n",
    "# Create a view on the data called loans_delta\n",
    "spark.read.format(\"delta\").load(deltaPath).createOrReplaceTempView(\"loans_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6adbc4b-fe1e-4069-9372-127f147dc18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and explore the data as easily as any other table\n",
    "spark.sql(\"select count(*) from loans_delta\").show()\n",
    "spark.sql(\"select * from loans_delta limit 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b80a45f-ce33-4d81-882c-b7d522373d0c",
   "metadata": {},
   "source": [
    "### Loading Data Streams into a Delta Lake Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e6c70-965c-4788-bec9-b61f15f1e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=\"string\")\n",
    "def random_state():\n",
    "  states = [\"CA\", \"TX\", \"NY\", \"WA\"]\n",
    "  return str(random.choice(states))\n",
    "\n",
    "newLoanStreamDF = (spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 5).load()\n",
    "    .withColumn(\"loan_id\", 10000 + F.col(\"value\"))\n",
    "    .withColumn(\"funded_amnt\", (F.rand() * 5000 + 5000).cast(\"integer\"))\n",
    "    .withColumn(\"paid_amnt\", F.col(\"funded_amnt\") - (F.rand() * 2000))\n",
    "    .withColumn(\"addr_state\", random_state())\n",
    "    .select(\"loan_id\", \"funded_amnt\", \"paid_amnt\", \"addr_state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b16440-182e-4dbf-a56f-67c5433de724",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointDir = f\"/tmp/spark-streaming-checkpoints-{uuid1()}\"\n",
    "trigger_processing_time = 2\n",
    "streamingQuery = (newLoanStreamDF.writeStream \n",
    "    .format(\"delta\") \n",
    "    .option(\"checkpointLocation\", checkpointDir) \n",
    "    .trigger(processingTime = f\"{trigger_processing_time} seconds\") \n",
    "    .start(deltaPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61baf6-87d0-4039-8824-902c809a2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this query several times with a pause inbetween to see that the row count changes,\n",
    "# because the streaming query is writing to the delta table.\n",
    "sleep(trigger_processing_time)\n",
    "spark.table(\"loans_delta\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3546233-f058-4dd0-b2ff-4ada0d5cbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamingQuery.stop()\n",
    "print(\"Status of streamingQuery:\", streamingQuery.status)\n",
    "print(\"Active streams:\", spark.streams.active)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a64714-b02c-4ee2-974a-d4ff95b5e3f5",
   "metadata": {},
   "source": [
    "### Enforcing Schema on Write to Prevent Data Corruption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef0ddb-b87f-4044-88e7-b0474fd14bc8",
   "metadata": {},
   "source": [
    "Trying to write some data with a schema inconsisten with that of the delta table. The new data has an additional column `closed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859e9ce-a587-4d49-895c-51ccfc4c9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take two entries form the `loans_delta` table and add the `closed` column to them.\n",
    "cols = ['loan_id', 'funded_amnt', 'paid_amnt', 'addr_state', 'closed']\n",
    "items = [\n",
    "    (1111111, 1000, 1000.0, 'TX', True), \n",
    "    (2222222, 2000, 0.0, 'CA', False)\n",
    "]\n",
    "\n",
    "loanUpdates = (spark.createDataFrame(items, cols)\n",
    "               .withColumn(\"funded_amnt\", F.col(\"funded_amnt\").cast(\"int\")))\n",
    "loanUpdates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2399514-004e-4611-b64d-6441dcafeced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to write the two entries with an extra column to the `loans_delta` table.\n",
    "# See the write failing with an `AnalysisException` because of a schema mismatch.\n",
    "loanUpdates.write.format(\"delta\").mode(\"append\").save(deltaPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf04917f-0481-4eec-8929-9d03d395a527",
   "metadata": {},
   "source": [
    "### Evolving Schemas to Accommodate Changing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0567e8ee-4e2f-47e0-a3ca-6fa7aad159ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `mergeSchema` option to add the entries with an extra column\n",
    "# and to update the table schema correspondingly.\n",
    "loanUpdates.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", True).save(deltaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84668ed5-fc8e-4498-93f3-db09fafcaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the new column `closed` we have to reread the delta table.\n",
    "loans_delta = spark.read.format(\"delta\").load(deltaPath)\n",
    "loans_delta.createOrReplaceTempView(\"loans_delta\")\n",
    "spark.sql(\"select * from loans_delta\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180fb8b-25f5-46d9-86c7-c467c71acb36",
   "metadata": {},
   "source": [
    "### Transforming Existing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e7e16-4f46-41d2-a600-2e59d5e371c5",
   "metadata": {},
   "source": [
    "#### Updating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e13bef-c137-46f0-bd25-a5517283feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801da6b-0662-417f-9af5-0adc64b77333",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_delta.where(F.expr(\"addr_state = 'OR'\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f05651-47bf-405b-be68-1b09f5e2a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, deltaPath)\n",
    "deltaTable.update(\"addr_state = 'OR'\",  {\"addr_state\": \"'WA'\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057a6db-39d4-44d7-acea-d4754598d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_delta.where(F.expr(\"addr_state = 'OR'\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e7dc5-0f14-4117-a6bb-d7d92a7896ac",
   "metadata": {},
   "source": [
    "#### Deleting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfd923-7f40-44dc-b674-48ee64b5daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_delta.where(F.expr(\"funded_amnt <= paid_amnt\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16610d3f-f019-4716-a2a5-cc4226eac8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.delete(\"funded_amnt <= paid_amnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4e348-2bba-4a5e-b600-2c09dd8d9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_delta.where(F.expr(\"funded_amnt <= paid_amnt\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4680aab-221a-473f-ab1c-40a3275e012e",
   "metadata": {},
   "source": [
    "#### Upserting data using `merge()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6b7cb-d937-44ad-a4b3-a96b51b4fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_items_id = [str(i) for i in next(zip(*items))]\n",
    "print(new_items_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32400d0a-6cca-4e49-bcad-f5dad9170242",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_delta.where(loans_delta.loan_id.isin(new_items_id)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492facf3-c063-4687-ae9c-72e2309ba583",
   "metadata": {},
   "outputs": [],
   "source": [
    "(deltaTable\n",
    " .alias(\"t\")\n",
    " .merge(loanUpdates.alias(\"s\"), \"t.loan_id = s.loan_id\")\n",
    " .whenMatchedUpdateAll()\n",
    " .whenNotMatchedInsertAll()\n",
    " .execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6652d74-8497-4ee3-a960-4deebb3bb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_delta.where(loans_delta.loan_id.isin(new_items_id)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ade84-8664-441f-afa1-d90cd8543067",
   "metadata": {},
   "source": [
    "#### Deduplicating data while inserting using insert-only merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1d76f-ec18-4aab-8675-dd71e4c5a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_delta.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbdbe8c-a333-4ca0-bf42-de876a5ecabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(deltaTable\n",
    " .alias(\"t\")\n",
    " .merge(loanUpdates.alias(\"s\"), \"t.loan_id = s.loan_id\")\n",
    " .whenNotMatchedInsertAll()\n",
    " .execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e95f391-3bef-4ef9-9453-7102fe05538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The count is the same as before the merge, because the dupplicate records\n",
    "# were not inserted.\n",
    "loans_delta.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16d7d7-02b5-4fd2-8837-8cf39f8f86e5",
   "metadata": {},
   "source": [
    "### Auditing Data Changes with Operation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705393e6-9e92-4e48-8a9a-865ce4878bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the table's operation history\n",
    "deltaTable.history().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d41e3e-c20c-4dd9-8ca1-ff21ead63f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the important columns from the history.\n",
    "# Columns `operation` and `operationParameters` are useful for auditing the changes.\n",
    "(deltaTable\n",
    "  .history(3)\n",
    "  .select(\"version\", \"timestamp\", \"operation\", \"operationParameters\")\n",
    "  .show(truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ab857-9cbe-4108-ae68-35a4ca9bdc24",
   "metadata": {},
   "source": [
    "### Querying Previous Snapshots of a Table with Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9f9ba-4995-43e7-ae80-92a82f874882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78ff66-eb81-40d4-abb3-d60de77fedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a previous version of the delta table by a commit timestamp.\n",
    "second_last_commit_timestamp = deltaTable.history(2).orderBy(\"version\", descending=True).first().timestamp.isoformat()\n",
    "(spark.read\n",
    "  .format(\"delta\")\n",
    "  .option(\"timestampAsOf\", second_last_commit_timestamp)\n",
    "  .load(deltaPath)).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef030ba0-1958-40f4-b350-cf2aefb11eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a previous version of the delta table by a version number.\n",
    "(spark.read.format(\"delta\")\n",
    "  .option(\"versionAsOf\", \"0\")\n",
    "  .load(deltaPath)).show(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
